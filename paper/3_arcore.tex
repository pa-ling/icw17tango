% !TEX root = main.tex

\section{Google ARCore}
Google ARCore ist ebenfalls eine Augmented-Reality-Plattform. Offiziell ist es nur auf den Google Pixel Phones und dem Samsung Galaxy S8 unterstützt. Nach dem Verlassen des Preview-Status sollen eine Vielzahl von Geräten mit Android 8 folgen. Im Gegensatz zu Tango wird keine zusätzliche Hardwäre benötigt, d.h. lediglich die Kamera, das Gyroskop und der Beschleunigungssensor werden verwendet, also Komponenten, die in jedem aktuellem Smartphone zu finden sind. Dabei basiert es auf drei fundamentalen Konzepten \cite{arcore_overview}:
\begin{enumerate}
	\item \textbf{Motion tracking:} Wie bei Tango wird per Feature Points im gesehenen Bild die Position und Ausrichtung des Geräts im Raum ermittelt. Daten aus dem Gyroskop und Beschleunigungssensor (IMU) des Telefons werden hierbei ebenfalls mit den Daten aus dem Bild kombiniert. \cite{arcore_fundamentals}
	
	Problem sind bei ruckartigen Bewegungen zu erwarten. Google Tango löste dieses Probleme mit dem Area Learning.
	
	\item \textbf{Environmental understanding:}  Durch Analyse der Feature Points werden flache Oberflächen erkannt und können z.B. mit Objekten bestückt werden. \cite{arcore_fundamentals}
	
	In Google Tango bietet z.B. die TangoPointCloud in der Unity-API per \texttt{findPlane}-Methode eine sehr ähnliche Funktionalität. Auch ARCore stellt eine Punktwolke zur Verfügung.
	
	\item \textbf{Light estimation:} Die reale Beleuchtung wird analysiert und ARCore stellt diese Informationen zur Verfügung, sodass virtuelle Objekte durch korrekte Beleuchtung realistischer aussehen. \cite{arcore_fundamentals}
	
	Ein solches Feature gibt es in der "`Google Tango"'-Plattform nicht.
\end{enumerate}

ARCore baut laut Google auf der Arbeit von Tango auf. Der Vergleich in Tabelle \ref{arcore_vs_tango} zeigt, dass sich beide sehr weit voneinander entfernen, was zum einen daran liegt, das beide mit unterschiedlichen Daten arbeiten. Zum Anderen könnte dies aber auch am Apple ARKit liegen, was später noch deutlicher wird.

Das Tango SDK ist komplexer und teilweise auch technischer aufgebaut, wobei bei ARCore die Einfachheit und der Anwendungszweck mehr im Vordergrund liegen. Wie viele Features genau dadurch verloren gehen ist ohne ARCore testen zu können schwer einzuschätzen. Da in den Dokumentation nichts zu Area Learning oder ähnlichem steht, fehlt dies aber vermutlich hier.

Schon in Vuforia, einem markerbasierten AR-Framework, werden jedoch in Markern visuelle Features verwendet um den Marker zu erkennen \cite{fehling}. Die gespeicherten Landmarken werden auch zum Großteil aus diesen bestehen, da die Lokalisierung bei schlechten Lichtverhältnissen teilweise nicht funktioniert. Also kann, sofern es noch nicht vorhanden ist, dies durchaus bis zum finalen Release implementiert werden.

\begin{table}[h]
	\centering
	\begin{tabular}{|p{4cm}|p{4cm}|}
		\hline
		\textbf{ARCore} & \textbf{Tango (Ausschnitt)}\\
		\hline
		Anchor & ---\\
		Config & TangoConfig\\
		Frame & TangoImageBuffer\\
		HitResult & ---\\
		LightEstimate & ---\\
		Plane & ---\\
		PlaneHitResult & TS.IntersectionPointPlaneModelPair\\
		PointCloud & TangoPointCloudData/ TangoPointCloudManager\\
		PointCloudHitResult & ---\\
		Pose & TangoPoseData\\
		Session & Tango\\
		--- & TangoAreaDescriptinMetaData\\
		--- & TangoCameraIntrinsics\\
		Session & TangoCameraNativeLoader\\
		--- & TangoCoordinateFramePair\\
		--- & TangoEvent\\
		--- & TangoTextureCameraPreview\\
		--- & TangoXyzIjData\\
		\hline
	\end{tabular}
	\caption{Gegenüberstellung der Schnittstellen von Google ARCore\cite{arcore_android_reference} und Google Tango\cite{tango_android_reference}\\
	Legende: TS = TangoSupport}
	\label{arcore_vs_tango}
\end{table}
